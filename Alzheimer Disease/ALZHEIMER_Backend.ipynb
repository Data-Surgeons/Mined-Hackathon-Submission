{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ht.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OpGrLm4KQWKW",
        "outputId": "49738eda-7e20-4445-8889-3236088bf08a"
      },
      "source": [
        "Xt = []\r\n",
        "X = []\r\n",
        "Y = []\r\n",
        "Yt = []\r\n",
        "import os\r\n",
        "from PIL import Image, ImageOps\r\n",
        "from numpy import asarray\r\n",
        " \r\n",
        "for fold in os.listdir('/content/drive/My Drive/al/test/1'):\r\n",
        "    fold = os.path.join('/content/drive/My Drive/al/test/1', fold)\r\n",
        "    for img in os.listdir(fold):\r\n",
        "      img_path = os.path.join(fold,img)\r\n",
        "      im = Image.open(img_path)\r\n",
        "      im1 = im.convert('L')\r\n",
        "      im2 = ImageOps.equalize(im1, mask = None)\r\n",
        "      im3 = im2.resize((128,128))   \r\n",
        "      data = asarray(im3)/255\r\n",
        "      Xt.append(data)\r\n",
        "      Yt.append(1)\r\n",
        "\r\n",
        "for img in os.listdir('/content/drive/My Drive/al/test/0'):\r\n",
        "    img_path = os.path.join('/content/drive/My Drive/al/test/0', img)\r\n",
        "    im = Image.open(img_path)\r\n",
        "    im = Image.open(img_path)\r\n",
        "    im1 = im.convert('L')\r\n",
        "    im2 = ImageOps.equalize(im1, mask = None)\r\n",
        "    im3 = im2.resize((128,128)) \r\n",
        "    data = asarray(im3)/255\r\n",
        "    Xt.append(data)\r\n",
        "    Yt.append(0)\r\n",
        "\r\n",
        "for fold in os.listdir('/content/drive/My Drive/al/train/1'):\r\n",
        "    fold = os.path.join('/content/drive/My Drive/al/train/1', fold)\r\n",
        "    for img in os.listdir(fold):\r\n",
        "      img_path = os.path.join(fold,img)\r\n",
        "      im = Image.open(img_path)\r\n",
        "      im1 = im.convert('L')\r\n",
        "      im2 = ImageOps.equalize(im1, mask = None)\r\n",
        "      im3 = im2.resize((128,128))  \r\n",
        "      data = asarray(im3)/255\r\n",
        "      X.append(data)\r\n",
        "      Y.append(1)\r\n",
        "\r\n",
        "\r\n",
        "for img in os.listdir('/content/drive/My Drive/al/train/0'):\r\n",
        "    img_path = os.path.join('/content/drive/My Drive/al/train/0', img)\r\n",
        "    im = Image.open(img_path)\r\n",
        "    im = Image.open(img_path)\r\n",
        "    im1 = im.convert('L')\r\n",
        "    im2 = ImageOps.equalize(im1, mask = None)\r\n",
        "    im3 = im2.resize((128,128))   \r\n",
        "    data = asarray(im3)/255\r\n",
        "    X.append(data)\r\n",
        "    Y.append(0)\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "X = np.asarray(X).astype('float')\r\n",
        "xt = X.reshape(X.shape[0],128,128,1)\r\n",
        "np.save('/content/drive/My Drive/al/xt.npy', xt)\r\n",
        "\r\n",
        "Xt = np.asarray(Xt).astype('float')\r\n",
        "xtt = Xt.reshape(Xt.shape[0],128,128,1)\r\n",
        "np.save('/content/drive/My Drive/al/xtt.npy', xtt)\r\n",
        "\r\n",
        "Y = np.vstack(Y)\r\n",
        "np.save('/content/drive/My Drive/al/yt.npy', Y)\r\n",
        "\r\n",
        "Yt = np.vstack(Yt)\r\n",
        "np.save('/content/drive/My Drive/al/ytt.npy', Yt)\r\n",
        "\r\n",
        "print(xt.shape)\r\n",
        "print(Y.shape)\r\n",
        "print(xtt.shape)\r\n",
        "print(Yt.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5121, 128, 128, 1)\n",
            "(5121, 1)\n",
            "(1279, 128, 128, 1)\n",
            "(1279, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m18fuXsmWywz",
        "outputId": "4ff62013-6ff9-447e-ccd4-43bec46d7f0b"
      },
      "source": [
        "import keras\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense, Dropout, Flatten\r\n",
        "from keras.layers import Conv2D, MaxPooling2D\r\n",
        "model = Sequential()\r\n",
        "model.add(Conv2D(32, kernel_size=(7, 7), activation='relu', input_shape=(128,128,1)))\r\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\r\n",
        "model.add(Dropout(0.2))\r\n",
        "\r\n",
        "model.add(Conv2D(64, kernel_size=(5, 5), activation='relu'))\r\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\r\n",
        "model.add(Dropout(0.2))\r\n",
        "\r\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\r\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\r\n",
        "\r\n",
        "model.add(Flatten())\r\n",
        "\r\n",
        "model.add(Dense(2, activation='softmax'))\r\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam',\r\n",
        "              metrics=['accuracy'])\r\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_170\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_12 (Conv2D)           (None, 122, 122, 32)      1600      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling (None, 61, 61, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 61, 61, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 57, 57, 64)        51264     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling (None, 28, 28, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 28, 28, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 26, 26, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_14 (MaxPooling (None, 13, 13, 128)       0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 21632)             0         \n",
            "_________________________________________________________________\n",
            "dense_581 (Dense)            (None, 2)                 43266     \n",
            "=================================================================\n",
            "Total params: 169,986\n",
            "Trainable params: 169,986\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWz_l1BmW1mB",
        "outputId": "30f4025a-4dd3-4d5b-d976-167b5edb7532"
      },
      "source": [
        "model.fit(xt,to_categorical(yt), epochs=15, validation_data=(xtt, to_categorical(ytt)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "161/161 [==============================] - 3s 21ms/step - loss: 0.5449 - accuracy: 0.7180 - val_loss: 0.6568 - val_accuracy: 0.6145\n",
            "Epoch 2/15\n",
            "161/161 [==============================] - 3s 21ms/step - loss: 0.5297 - accuracy: 0.7415 - val_loss: 0.6487 - val_accuracy: 0.6145\n",
            "Epoch 3/15\n",
            "161/161 [==============================] - 3s 20ms/step - loss: 0.5216 - accuracy: 0.7376 - val_loss: 0.6733 - val_accuracy: 0.5825\n",
            "Epoch 4/15\n",
            "161/161 [==============================] - 3s 21ms/step - loss: 0.5155 - accuracy: 0.7436 - val_loss: 0.6480 - val_accuracy: 0.6216\n",
            "Epoch 5/15\n",
            "161/161 [==============================] - 3s 20ms/step - loss: 0.5072 - accuracy: 0.7499 - val_loss: 0.6577 - val_accuracy: 0.6028\n",
            "Epoch 6/15\n",
            "161/161 [==============================] - 3s 21ms/step - loss: 0.5033 - accuracy: 0.7534 - val_loss: 0.6528 - val_accuracy: 0.6122\n",
            "Epoch 7/15\n",
            "161/161 [==============================] - 3s 20ms/step - loss: 0.4877 - accuracy: 0.7602 - val_loss: 0.6566 - val_accuracy: 0.5973\n",
            "Epoch 8/15\n",
            "161/161 [==============================] - 3s 21ms/step - loss: 0.4787 - accuracy: 0.7643 - val_loss: 0.7049 - val_accuracy: 0.5817\n",
            "Epoch 9/15\n",
            "161/161 [==============================] - 3s 21ms/step - loss: 0.4752 - accuracy: 0.7668 - val_loss: 0.6621 - val_accuracy: 0.6067\n",
            "Epoch 10/15\n",
            "161/161 [==============================] - 3s 21ms/step - loss: 0.4649 - accuracy: 0.7774 - val_loss: 0.6821 - val_accuracy: 0.5841\n",
            "Epoch 11/15\n",
            "161/161 [==============================] - 3s 20ms/step - loss: 0.4624 - accuracy: 0.7737 - val_loss: 0.6641 - val_accuracy: 0.6122\n",
            "Epoch 12/15\n",
            "161/161 [==============================] - 3s 21ms/step - loss: 0.4505 - accuracy: 0.7846 - val_loss: 0.6786 - val_accuracy: 0.6036\n",
            "Epoch 13/15\n",
            "161/161 [==============================] - 3s 20ms/step - loss: 0.4500 - accuracy: 0.7872 - val_loss: 0.6840 - val_accuracy: 0.5841\n",
            "Epoch 14/15\n",
            "161/161 [==============================] - 3s 20ms/step - loss: 0.4427 - accuracy: 0.7868 - val_loss: 0.7142 - val_accuracy: 0.5676\n",
            "Epoch 15/15\n",
            "161/161 [==============================] - 3s 20ms/step - loss: 0.4441 - accuracy: 0.7819 - val_loss: 0.7621 - val_accuracy: 0.5653\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fae83300f10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 338
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Mj87C0DWzwo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mx2ce8v4Xw3_",
        "outputId": "e988efb3-ee49-4e28-e66f-7c428f497844"
      },
      "source": [
        "import numpy as np\r\n",
        "xt = np.load('/content/drive/My Drive/al/xt.npy')\r\n",
        "xtt = np.load('/content/drive/My Drive/al/xtt.npy')\r\n",
        "yt = np.load('/content/drive/My Drive/al/yt.npy')\r\n",
        "ytt = np.load('/content/drive/My Drive/al/ytt.npy')\r\n",
        "\r\n",
        "\r\n",
        "print(xt.shape)\r\n",
        "print(yt.shape)\r\n",
        "print(xtt.shape)\r\n",
        "print(ytt.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5121, 128, 128, 1)\n",
            "(5121, 1)\n",
            "(1279, 128, 128, 1)\n",
            "(1279, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYBq34PO94qO"
      },
      "source": [
        "import keras\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense, Dropout, Flatten\r\n",
        "from keras.layers import Conv2D, MaxPooling2D\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5rBIrHkavSF"
      },
      "source": [
        "from keras.models import Model\r\n",
        "from keras.layers import Add, Activation, Concatenate, Conv2D, Dropout, Dense \r\n",
        "from keras.layers import Flatten, Input, GlobalAveragePooling2D, MaxPooling2D\r\n",
        "import keras.backend as K\r\n",
        "\r\n",
        "def SqueezeNet_11(input_shape, nb, compression=0.25):\r\n",
        "    input_img = Input(shape=input_shape)\r\n",
        "\r\n",
        "    x = Conv2D(int(64*compression), (3,3), activation='relu', strides=(2,2), padding='same', name='conv1')(input_img)\r\n",
        "\r\n",
        "    x = MaxPooling2D(pool_size=(3,3), strides=(2,2), name='maxpool1')(x)\r\n",
        "    \r\n",
        "    x = create_fire_module(x, int(16*compression), name='fire2')\r\n",
        "    x = create_fire_module(x, int(16*compression), name='fire3')\r\n",
        "    \r\n",
        "    x = MaxPooling2D(pool_size=(3,3), strides=(2,2), name='maxpool3')(x)\r\n",
        "    \r\n",
        "    x = create_fire_module(x, int(32*compression), name='fire4')\r\n",
        "    x = create_fire_module(x, int(32*compression), name='fire5')\r\n",
        "    \r\n",
        "    x = MaxPooling2D(pool_size=(3,3), strides=(2,2), name='maxpool5')(x)\r\n",
        "    \r\n",
        "    x = create_fire_module(x, int(48*compression), name='fire6')\r\n",
        "    x = create_fire_module(x, int(48*compression), name='fire7')\r\n",
        "    x = create_fire_module(x, int(64*compression), name='fire8')\r\n",
        "    x = create_fire_module(x, int(64*compression), name='fire9')\r\n",
        "\r\n",
        "    x = Flatten()(x)\r\n",
        "    x = Dense(nb)(x)\r\n",
        "\r\n",
        "    return Model(inputs=input_img, outputs=x)\r\n",
        "\r\n",
        "\r\n",
        "def create_fire_module(x, nb_squeeze_filter, name, use_bypass=False):\r\n",
        "    \"\"\"\r\n",
        "    Creates a fire module\r\n",
        "    \r\n",
        "    Arguments:\r\n",
        "        x                 : input\r\n",
        "        nb_squeeze_filter : number of filters of squeeze. The filtersize of expand is 4 times of squeeze\r\n",
        "        use_bypass        : if True then a bypass will be added\r\n",
        "        name              : name of module e.g. fire123\r\n",
        "    \r\n",
        "    Returns:\r\n",
        "        x                 : returns a fire module\r\n",
        "    \"\"\"\r\n",
        "    \r\n",
        "    nb_expand_filter = 4 * nb_squeeze_filter\r\n",
        "    squeeze    = Conv2D(nb_squeeze_filter,(1,1), activation='relu', padding='same', name='%s_squeeze'%name)(x)\r\n",
        "    expand_1x1 = Conv2D(nb_expand_filter, (1,1), activation='relu', padding='same', name='%s_expand_1x1'%name)(squeeze)\r\n",
        "    expand_3x3 = Conv2D(nb_expand_filter, (3,3), activation='relu', padding='same', name='%s_expand_3x3'%name)(squeeze)\r\n",
        "    \r\n",
        "    axis = get_axis()\r\n",
        "    x_ret = Concatenate(axis=axis, name='%s_concatenate'%name)([expand_1x1, expand_3x3])\r\n",
        "    \r\n",
        "    if use_bypass:\r\n",
        "        x_ret = Add(name='%s_concatenate_bypass'%name)([x_ret, x])\r\n",
        "        \r\n",
        "    return x_ret\r\n",
        "\r\n",
        "\r\n",
        "def get_axis():\r\n",
        "    axis = -1 if K.image_data_format() == 'channels_last' else 1\r\n",
        "    return axis"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8x_F7gqRcVPV",
        "outputId": "408576c7-895f-46d3-8f84-c11fbb6461ff"
      },
      "source": [
        "import random\r\n",
        "# First let's separate the dataset from 1 matrix to a list of matricies\r\n",
        "image_list = xt\r\n",
        "label_list = yt\r\n",
        "left_input = []\r\n",
        "right_input = []\r\n",
        "targets = []\r\n",
        "ones = 6000\r\n",
        "zeros = 6000\r\n",
        "#Number of pairs per image\r\n",
        "pairs = 200\r\n",
        "#the new dataset to train on\r\n",
        "for i in range(len(label_list)):\r\n",
        "    for _ in range(pairs):\r\n",
        "        compare_to = i\r\n",
        "        while compare_to == i: #Make sure it's not comparing to itself\r\n",
        "            compare_to = random.randint(0,xt.shape[0]-1)\r\n",
        "            if (label_list[i] == label_list[compare_to]):\r\n",
        "              if(ones != 0):\r\n",
        "                targets.append(1.)\r\n",
        "                ones = ones - 1\r\n",
        "                left_input.append(image_list[i])\r\n",
        "                right_input.append(image_list[compare_to])\r\n",
        "            else:\r\n",
        "              if(zeros != 0):\r\n",
        "                targets.append(0.)\r\n",
        "                zeros = zeros - 1\r\n",
        "                left_input.append(image_list[i])\r\n",
        "                right_input.append(image_list[compare_to])\r\n",
        "\r\n",
        "            \r\n",
        "left_input = np.squeeze(np.array(left_input))\r\n",
        "right_input = np.squeeze(np.array(right_input))\r\n",
        "targets = np.squeeze(np.array(targets))\r\n",
        "t = np.reshape(targets,(targets.shape[0],1))\r\n",
        "li = left_input.reshape(left_input.shape[0],128,128,1)\r\n",
        "ri = right_input.reshape(right_input.shape[0],128,128,1)\r\n",
        "\r\n",
        "li.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12000, 128, 128, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPD9_fn4eJHF",
        "outputId": "096f9aa9-e1bb-4443-bd4d-2b870574d6df"
      },
      "source": [
        "from keras.optimizers import Adam\r\n",
        "from keras.models import Model, Sequential\r\n",
        "from keras.layers import Input\r\n",
        "from keras.layers.merge import Concatenate\r\n",
        "from keras.layers.core import Lambda\r\n",
        "from keras import backend as K\r\n",
        "left_input = Input((128,128,1))\r\n",
        "right_input = Input((128,128,1))\r\n",
        "\r\n",
        "#model = SqueezeNet_11((128,128,1), 128, 0.5)\r\n",
        "\r\n",
        "model = Sequential()\r\n",
        "model.add(Conv2D(32, (3,3), activation='relu', input_shape=(128,128,1)))\r\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\r\n",
        "model.add(Conv2D(64, (3,3), activation='relu'))\r\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\r\n",
        "model.add(Conv2D(128, (3,3), activation='relu'))\r\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\r\n",
        "\r\n",
        "model.add(Flatten())\r\n",
        "model.add(Dense(256, activation='sigmoid'))\r\n",
        "\r\n",
        "\r\n",
        "encoded_l = model(left_input)\r\n",
        "encoded_r = model(right_input)\r\n",
        "\r\n",
        "# Getting the L1 Distance between the 2 encodings\r\n",
        "L1_layer = Lambda(lambda tensor:K.abs(tensor[0] - tensor[1]))\r\n",
        "\r\n",
        "# Add the distance function to the network\r\n",
        "L1_distance = L1_layer([encoded_l, encoded_r])\r\n",
        "\r\n",
        "prediction = Dense(1,activation='sigmoid')(L1_distance)\r\n",
        "siamese_net = Model(inputs=[left_input,right_input],outputs=prediction)\r\n",
        "\r\n",
        "optimizer = Adam(0.0001)\r\n",
        "#//TODO: get layerwise learning rates and momentum annealing scheme described in paperworking\r\n",
        "siamese_net.compile(loss=\"binary_crossentropy\",optimizer=optimizer,metrics=['accuracy'])\r\n",
        "siamese_net.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_6 (InputLayer)            [(None, 128, 128, 1) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_7 (InputLayer)            [(None, 128, 128, 1) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sequential_1 (Sequential)       (None, 256)          6515456     input_6[0][0]                    \n",
            "                                                                 input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 256)          0           sequential_1[0][0]               \n",
            "                                                                 sequential_1[1][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 1)            257         lambda_1[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 6,515,713\n",
            "Trainable params: 6,515,713\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UG3M_0m8j1il",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e505d483-b03d-4a07-b293-648ba8707d0a"
      },
      "source": [
        "siamese_net.fit([li,ri], t,\r\n",
        "                batch_size=10,\r\n",
        "                epochs=10, validation_split = 0.1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1080/1080 [==============================] - 14s 13ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.2394 - val_accuracy: 0.9092\n",
            "Epoch 2/10\n",
            "1080/1080 [==============================] - 14s 13ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0716 - val_accuracy: 0.9692\n",
            "Epoch 3/10\n",
            "1080/1080 [==============================] - 14s 13ms/step - loss: 0.0288 - accuracy: 0.9978 - val_loss: 0.1012 - val_accuracy: 0.9625\n",
            "Epoch 4/10\n",
            "1080/1080 [==============================] - 14s 13ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.1230 - val_accuracy: 0.9483\n",
            "Epoch 5/10\n",
            "1080/1080 [==============================] - 14s 13ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0559 - val_accuracy: 0.9825\n",
            "Epoch 6/10\n",
            "1080/1080 [==============================] - 14s 13ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0597 - val_accuracy: 0.9783\n",
            "Epoch 7/10\n",
            "1080/1080 [==============================] - 14s 13ms/step - loss: 0.0241 - accuracy: 0.9976 - val_loss: 0.1670 - val_accuracy: 0.9692\n",
            "Epoch 8/10\n",
            "1080/1080 [==============================] - 14s 13ms/step - loss: 0.0300 - accuracy: 0.9993 - val_loss: 0.1068 - val_accuracy: 0.9875\n",
            "Epoch 9/10\n",
            "1080/1080 [==============================] - 14s 13ms/step - loss: 0.0141 - accuracy: 0.9999 - val_loss: 0.0783 - val_accuracy: 0.9908\n",
            "Epoch 10/10\n",
            "1080/1080 [==============================] - 14s 13ms/step - loss: 0.0230 - accuracy: 0.9993 - val_loss: 0.1073 - val_accuracy: 0.9917\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7faf9c1f3a10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ura7pXmzehn"
      },
      "source": [
        "import keras\r\n",
        "model.save('/content/drive/My Drive/al/emb2.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQ8kA2e90fSO",
        "outputId": "668bf62e-c1d8-4789-8639-4a94f088098b"
      },
      "source": [
        "import keras\r\n",
        "emb = keras.models.load_model('/content/drive/My Drive/al/emb2.h5')\r\n",
        "xt = emb.predict(xt)\r\n",
        "xtt = emb.predict(xtt)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "id": "s2aoeJpmQMqt",
        "outputId": "16a952f4-9179-4f89-9959-d85ecca090d9"
      },
      "source": [
        "\r\n",
        "xt = model.predict(xt)\r\n",
        "xtt = model.predict(xtt)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-74-794e0aab0f5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mxt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mxtt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1627\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1628\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1629\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1631\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    860\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2939\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m-> 2941\u001b[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3356\u001b[0m               call_context_key in self._function_cache.missed):\n\u001b[1;32m   3357\u001b[0m             return self._define_function_with_shape_relaxation(\n\u001b[0;32m-> 3358\u001b[0;31m                 args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[0m\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[0;34m(self, args, kwargs, flat_args, filtered_flat_args, cache_key_context)\u001b[0m\n\u001b[1;32m   3278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3279\u001b[0m     graph_function = self._create_graph_function(\n\u001b[0;32m-> 3280\u001b[0;31m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[0m\u001b[1;32m   3281\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1478 predict_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1468 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1461 run_step  **\n        outputs = model.predict_step(data)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1434 predict_step\n        return self(x, training=False)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/input_spec.py:239 assert_input_compatibility\n        str(tuple(shape)))\n\n    ValueError: Input 0 of layer sequential_1 is incompatible with the layer: : expected min_ndim=4, found ndim=2. Full shape received: (None, 256)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNjhqMpHpgKj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd8519f3-3f44-4996-921c-e34dfb213e82"
      },
      "source": [
        "from keras.utils import to_categorical\r\n",
        "ylbd = to_categorical(yt)\r\n",
        "alp = 0.2\r\n",
        "xaug = []\r\n",
        "yaug = []\r\n",
        "for k in range(0,xt.shape[0]):\r\n",
        "  cnt = 0\r\n",
        "  for cnt in range(0,2):\r\n",
        "    lbd =np.random.beta(alp,alp)\r\n",
        "    yks = np.random.randint(xt.shape[0])\r\n",
        "    kdash = xt[yks]\r\n",
        "    ydash = ylbd[yks]\r\n",
        "    kdash1 = xt[k]\r\n",
        "    ydash1 = ylbd[k]\r\n",
        "    xaug1 = kdash1*lbd + kdash*(1-lbd)\r\n",
        "    yaug1 = ydash1*lbd + ydash*(1-lbd)\r\n",
        "    xaug.append(xaug1)\r\n",
        "    yaug.append(yaug1)\r\n",
        "xs2 = np.asarray(xaug)\r\n",
        "ys2 = np.asarray(yaug)\r\n",
        "x1 = np.concatenate((xt,xs2))\r\n",
        "y1 = np.concatenate((ylbd,ys2))\r\n",
        "print(x1.shape)\r\n",
        "print(y1.shape)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(15363, 256)\n",
            "(15363, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGNO8ocT1SF9",
        "outputId": "02e29cd0-b34e-43b6-e554-77808066ead5"
      },
      "source": [
        "from keras.models import Model, Sequential\r\n",
        "\r\n",
        "Classifier_model = Sequential()\r\n",
        "#add model layers\r\n",
        "Classifier_model.Input = (256,)\r\n",
        "\r\n",
        "Classifier_model.add(Dense(512,activation='relu'))\r\n",
        "Classifier_model.add(Dense(512,activation='relu'))\r\n",
        "\r\n",
        "\r\n",
        "Classifier_model.add(Dense(2, activation='softmax'))\r\n",
        "\r\n",
        "Classifier_model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\r\n",
        "Classifier_model.fit(xt,to_categorical(yt),epochs=10, validation_data = (xtt,to_categorical(ytt)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "161/161 [==============================] - 1s 3ms/step - loss: 0.0792 - accuracy: 0.9762 - val_loss: 1.5425 - val_accuracy: 0.6787\n",
            "Epoch 2/10\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.0044 - accuracy: 0.9989 - val_loss: 1.6733 - val_accuracy: 0.6959\n",
            "Epoch 3/10\n",
            "161/161 [==============================] - 1s 3ms/step - loss: 0.0090 - accuracy: 0.9982 - val_loss: 2.3583 - val_accuracy: 0.6677\n",
            "Epoch 4/10\n",
            "161/161 [==============================] - 1s 3ms/step - loss: 0.0096 - accuracy: 0.9969 - val_loss: 2.5481 - val_accuracy: 0.6638\n",
            "Epoch 5/10\n",
            "161/161 [==============================] - 0s 3ms/step - loss: 0.0049 - accuracy: 0.9982 - val_loss: 2.1826 - val_accuracy: 0.6708\n",
            "Epoch 6/10\n",
            "161/161 [==============================] - 1s 3ms/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 2.2209 - val_accuracy: 0.6724\n",
            "Epoch 7/10\n",
            "161/161 [==============================] - 1s 3ms/step - loss: 0.0072 - accuracy: 0.9989 - val_loss: 1.7293 - val_accuracy: 0.6904\n",
            "Epoch 8/10\n",
            "161/161 [==============================] - 1s 3ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 1.7696 - val_accuracy: 0.6888\n",
            "Epoch 9/10\n",
            "161/161 [==============================] - 1s 3ms/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 1.5124 - val_accuracy: 0.6865\n",
            "Epoch 10/10\n",
            "161/161 [==============================] - 1s 3ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 2.5443 - val_accuracy: 0.6599\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fad99707510>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 519
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpzMxjnY1giR"
      },
      "source": [
        "Classifier_model.save('/content/drive/My Drive/al/cff2.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1-mpruN2__0",
        "outputId": "ad0e3fb2-a692-48ca-ebe7-f21588444f60"
      },
      "source": [
        "inp = Input((128,128,1))\r\n",
        "e1 = keras.models.load_model('/content/drive/My Drive/al/emb2.h5')\r\n",
        "emb = e1(inp)\r\n",
        "c1 = keras.models.load_model('/content/drive/My Drive/al/cff2.h5')\r\n",
        "cff = c1(emb)\r\n",
        "fm = Model(inputs=inp,outputs=cff)\r\n",
        "fm.compile(loss='categorical_crossentropy', metrics=['accuracy'] )\r\n",
        "fm.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "Model: \"model_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_17 (InputLayer)        [(None, 128, 128, 1)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_1 (Sequential)    (None, 256)               6515456   \n",
            "_________________________________________________________________\n",
            "sequential_262 (Sequential)  (None, 2)                 658946    \n",
            "=================================================================\n",
            "Total params: 7,174,402\n",
            "Trainable params: 7,174,402\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLgwOILw4xiB"
      },
      "source": [
        "import numpy as np\r\n",
        "import keras\r\n",
        "xt1t = np.load('/content/drive/My Drive/al/xtt.npy')\r\n",
        "ytt = np.load('/content/drive/My Drive/al/ytt.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJDscs9J8f6P",
        "outputId": "7e8ca904-1d2c-48ae-bcca-79eb70cdd085"
      },
      "source": [
        "from keras.utils import to_categorical\r\n",
        "\r\n",
        "fm = keras.models.load_model('/content/drive/My Drive/al/fm.h5')\r\n",
        "fm.evaluate(xt1t,to_categorical(ytt))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "40/40 [==============================] - 0s 8ms/step - loss: 3.2350 - accuracy: 0.6927\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3.2349510192871094, 0.6927286982536316]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 521
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnORehh0KGeA",
        "outputId": "110cea0b-af87-46e6-de94-50c744cb73cd"
      },
      "source": [
        "fm.evaluate(xt1t,to_categorical(ytt))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "40/40 [==============================] - 0s 8ms/step - loss: 3.2350 - accuracy: 0.6927\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3.2349510192871094, 0.6927286982536316]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 523
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tc9LKCrvUP1l",
        "outputId": "5871f032-35f9-47fd-b5dd-07a628f182b6"
      },
      "source": [
        "fm.predict(xt1t)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.2073221e-01, 8.7926781e-01],\n",
              "       [2.7187693e-07, 9.9999976e-01],\n",
              "       [5.9171412e-02, 9.4082856e-01],\n",
              "       ...,\n",
              "       [1.0000000e+00, 7.6088442e-09],\n",
              "       [1.0000000e+00, 7.0854753e-13],\n",
              "       [7.1076721e-02, 9.2892325e-01]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 524
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ya5Uqk0C8aY9"
      },
      "source": [
        "fm.save('/content/drive/My Drive/al/fm.h5')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}