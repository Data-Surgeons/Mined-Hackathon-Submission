{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Skin_Backend.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOKLzJUXo0gU"
      },
      "source": [
        "E-Mixup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xxSlxQxicTt"
      },
      "source": [
        "'''\r\n",
        "from keras.utils import to_categorical\r\n",
        "ylbd = to_categorical(yt)\r\n",
        "alp = 0.2\r\n",
        "xaug = []\r\n",
        "yaug = []\r\n",
        "for k in range(0,xt.shape[0]):\r\n",
        "  cnt = 0\r\n",
        "  for cnt in range(0,2):\r\n",
        "    lbd =np.random.beta(alp,alp)\r\n",
        "    yks = np.random.randint(xt.shape[0])\r\n",
        "    kdash = xt[yks]\r\n",
        "    ydash = ylbd[yks]\r\n",
        "    kdash1 = xt[k]\r\n",
        "    ydash1 = ylbd[k]\r\n",
        "    xaug1 = kdash1*lbd + kdash*(1-lbd)\r\n",
        "    yaug1 = ydash1*lbd + ydash*(1-lbd)\r\n",
        "    xaug.append(xaug1)\r\n",
        "    yaug.append(yaug1)\r\n",
        "xs2 = np.asarray(xaug)\r\n",
        "ys2 = np.asarray(yaug)\r\n",
        "x1 = np.concatenate((xt,xs2))\r\n",
        "y1 = np.concatenate((ylbd,ys2))\r\n",
        "print(x1.shape)\r\n",
        "print(y1.shape)\r\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlXY735DpHL8"
      },
      "source": [
        "Siamese Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhZ4J4b7pJQ0"
      },
      "source": [
        "'''\r\n",
        "from keras.optimizers import Adam\r\n",
        "from keras.models import Model, Sequential\r\n",
        "from keras.layers import Input\r\n",
        "from keras.layers.merge import Concatenate\r\n",
        "from keras.layers.core import Lambda\r\n",
        "from keras import backend as K\r\n",
        "left_input = Input((128,128,1))\r\n",
        "right_input = Input((128,128,1))\r\n",
        "\r\n",
        "model = Sequential()\r\n",
        "model.add(Conv2D(32, (3,3), activation='relu', input_shape=(128,128,1)))\r\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\r\n",
        "model.add(Conv2D(64, (3,3), activation='relu'))\r\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\r\n",
        "model.add(Conv2D(128, (3,3), activation='relu'))\r\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\r\n",
        "\r\n",
        "model.add(Flatten())\r\n",
        "model.add(Dense(256, activation='sigmoid'))\r\n",
        "\r\n",
        "\r\n",
        "encoded_l = model(left_input)\r\n",
        "encoded_r = model(right_input)\r\n",
        "\r\n",
        "# Getting the L1 Distance between the 2 encodings\r\n",
        "L1_layer = Lambda(lambda tensor:K.abs(tensor[0] - tensor[1]))\r\n",
        "\r\n",
        "# Add the distance function to the network\r\n",
        "L1_distance = L1_layer([encoded_l, encoded_r])\r\n",
        "\r\n",
        "prediction = Dense(1,activation='sigmoid')(L1_distance)\r\n",
        "siamese_net = Model(inputs=[left_input,right_input],outputs=prediction)\r\n",
        "\r\n",
        "optimizer = Adam(0.0001)\r\n",
        "#//TODO: get layerwise learning rates and momentum annealing scheme described in paperworking\r\n",
        "siamese_net.compile(loss=\"binary_crossentropy\",optimizer=optimizer,metrics=['accuracy'])\r\n",
        "siamese_net.summary()\r\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15Ng7JA7pSVj"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLQP5QHHpGvU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}